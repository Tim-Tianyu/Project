{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "import random\n",
    "import CustomDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp.reload(CustomDataset)\n",
    "import CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset_dic = CustomDataset.load_all_datasets()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['MNIST_linear_unbalanced_1', 'CIFAR10_linear_unbalanced_1', 'MNIST_linear_unbalanced_2', 'CIFAR10_linear_unbalanced_2', 'MNIST_balanced', 'CIFAR10_balanced', 'MNIST_expo_unbalance', 'CIFAR10_expo_unbalance'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dic.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f9a19b3da50>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 3\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 50\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    network.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            train_losses.append(loss.item())\n",
    "            train_counter.append(\n",
    "                (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "            torch.save(network.state_dict(), 'results/model.pth')\n",
    "            torch.save(optimizer.state_dict(), 'results/optimizer.pth')\n",
    "\n",
    "def test():\n",
    "    network.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    cm = np.zeros((10,10))\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = network(data)\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "            cm = cm + confusion_matrix(np.array(target), np.array(pred), labels=[0,1,2,3,4,5,6,7,8,9])\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset), \n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    print(cm.astype('int'))\n",
    "    \n",
    "    tp = np.max(np.eye(10)*cm,1)\n",
    "    tp_and_fn = np.sum(cm, axis=1)\n",
    "    tp_and_fp = np.sum(cm, axis=0)\n",
    "    \n",
    "    print(\"percision:\")\n",
    "    print(tp / (tp_and_fn+0.001))\n",
    "    print(\"recall:\")\n",
    "    print(tp / (tp_and_fp+0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader((dataset_dic['MNIST_balanced']),batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('./data', train=False, download=False,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Net()\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)\n",
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/inf.ed.ac.uk/user/s16/s1636732/miniconda3/envs/mlp/lib/python3.7/site-packages/ipykernel_launcher.py:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 2.3316, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "[[   0  965    0    0   15    0    0    0    0    0]\n",
      " [   0 1135    0    0    0    0    0    0    0    0]\n",
      " [   0 1027    0    0    5    0    0    0    0    0]\n",
      " [   0 1010    0    0    0    0    0    0    0    0]\n",
      " [   0  980    0    0    2    0    0    0    0    0]\n",
      " [   0  885    0    0    7    0    0    0    0    0]\n",
      " [   0  922    0    0   36    0    0    0    0    0]\n",
      " [   0 1028    0    0    0    0    0    0    0    0]\n",
      " [   0  970    0    0    4    0    0    0    0    0]\n",
      " [   0 1002    0    0    7    0    0    0    0    0]]\n",
      "percision:\n",
      "[0.         0.99999912 0.         0.         0.00203666 0.\n",
      " 0.         0.         0.         0.        ]\n",
      "recall:\n",
      "[0.         0.11436919 0.         0.         0.02631544 0.\n",
      " 0.         0.         0.         0.        ]\n",
      "Train Epoch: 1 [0/27500 (0%)]\tLoss: 2.372260\n",
      "Train Epoch: 1 [3200/27500 (12%)]\tLoss: 2.263137\n",
      "Train Epoch: 1 [6400/27500 (23%)]\tLoss: 2.013866\n",
      "Train Epoch: 1 [9600/27500 (35%)]\tLoss: 1.680096\n",
      "Train Epoch: 1 [12800/27500 (47%)]\tLoss: 1.188190\n",
      "Train Epoch: 1 [16000/27500 (58%)]\tLoss: 1.093405\n",
      "Train Epoch: 1 [19200/27500 (70%)]\tLoss: 1.118452\n",
      "Train Epoch: 1 [22400/27500 (81%)]\tLoss: 0.730433\n",
      "Train Epoch: 1 [25600/27500 (93%)]\tLoss: 0.757697\n",
      "\n",
      "Test set: Avg. loss: 0.3504, Accuracy: 9065/10000 (90%)\n",
      "\n",
      "[[ 962    0    1    2    0    6    4    2    3    0]\n",
      " [   0 1117    5    4    0    1    3    0    5    0]\n",
      " [  11    6  935   10   14    0   17   22   14    3]\n",
      " [   2    3   21  937    0   16    1   16   10    4]\n",
      " [   1    5    1    1  885    1   25    2    5   56]\n",
      " [  16   10    2   32    5  781   18    4   19    5]\n",
      " [  14    4    4    1    9   24  901    1    0    0]\n",
      " [   8   27   39    4    3    0    0  890    2   55]\n",
      " [  10   17   15   31   14   27   11   16  807   26]\n",
      " [  17    7    6   13   35   11    2   64    4  850]]\n",
      "percision:\n",
      "[0.98163165 0.9841401  0.90600687 0.92772185 0.90122108 0.87555956\n",
      " 0.94050006 0.86575791 0.82854124 0.8424174 ]\n",
      "recall:\n",
      "[0.92411054 0.93394571 0.90864829 0.90531313 0.9170975  0.90080634\n",
      " 0.91751434 0.87512205 0.92865256 0.85085   ]\n",
      "Train Epoch: 2 [0/27500 (0%)]\tLoss: 0.659353\n",
      "Train Epoch: 2 [3200/27500 (12%)]\tLoss: 0.708259\n",
      "Train Epoch: 2 [6400/27500 (23%)]\tLoss: 0.580796\n",
      "Train Epoch: 2 [9600/27500 (35%)]\tLoss: 0.418918\n",
      "Train Epoch: 2 [12800/27500 (47%)]\tLoss: 0.660775\n",
      "Train Epoch: 2 [16000/27500 (58%)]\tLoss: 0.675435\n",
      "Train Epoch: 2 [19200/27500 (70%)]\tLoss: 0.433259\n",
      "Train Epoch: 2 [22400/27500 (81%)]\tLoss: 0.526523\n",
      "Train Epoch: 2 [25600/27500 (93%)]\tLoss: 0.709170\n",
      "\n",
      "Test set: Avg. loss: 0.2174, Accuracy: 9340/10000 (93%)\n",
      "\n",
      "[[ 970    0    0    1    0    3    3    1    2    0]\n",
      " [   0 1111    4    1    1    0    4    2   11    1]\n",
      " [  12    1  960    5   10    0   11   24    8    1]\n",
      " [   6    0   27  916    0   25    0   11   12   13]\n",
      " [   2    1    0    0  935    0   12    0    3   29]\n",
      " [  15    2    0    6    3  829   21    2    9    5]\n",
      " [  12    2    3    0   10   12  919    0    0    0]\n",
      " [   4    7   40    2    1    0    0  916    4   54]\n",
      " [   8    4   10    8   16   23    7    9  854   35]\n",
      " [  11    5    5    1   17   15    0   23    2  930]]\n",
      "percision:\n",
      "[0.98979491 0.97885376 0.93023166 0.9069298  0.95213752 0.92937116\n",
      " 0.95928919 0.89104972 0.87679581 0.92170374]\n",
      "recall:\n",
      "[0.93269141 0.98058166 0.91515642 0.97446705 0.94159019 0.9140012\n",
      " 0.94063363 0.92712457 0.94364537 0.8707857 ]\n",
      "Train Epoch: 3 [0/27500 (0%)]\tLoss: 0.293416\n",
      "Train Epoch: 3 [3200/27500 (12%)]\tLoss: 0.351588\n",
      "Train Epoch: 3 [6400/27500 (23%)]\tLoss: 0.529682\n",
      "Train Epoch: 3 [9600/27500 (35%)]\tLoss: 0.370968\n",
      "Train Epoch: 3 [12800/27500 (47%)]\tLoss: 0.826690\n",
      "Train Epoch: 3 [16000/27500 (58%)]\tLoss: 0.457682\n",
      "Train Epoch: 3 [19200/27500 (70%)]\tLoss: 0.564312\n",
      "Train Epoch: 3 [22400/27500 (81%)]\tLoss: 0.476907\n",
      "Train Epoch: 3 [25600/27500 (93%)]\tLoss: 0.490644\n",
      "\n",
      "Test set: Avg. loss: 0.1582, Accuracy: 9502/10000 (95%)\n",
      "\n",
      "[[ 969    0    1    1    0    1    5    1    2    0]\n",
      " [   0 1110    3    3    0    0    4    0   14    1]\n",
      " [  13    1  980    5    5    0    5   14    8    1]\n",
      " [   1    0   21  958    0   13    1    7    6    3]\n",
      " [   2    2    1    0  939    0   10    1    2   25]\n",
      " [   7    0    0   11    0  856    9    2    6    1]\n",
      " [   9    3    1    0    8   13  923    0    1    0]\n",
      " [   3    6   47    2    2    0    0  924    5   39]\n",
      " [   8    1    6    5    7   16    6    6  903   16]\n",
      " [   9    5    2    3   13   17    1   16    3  940]]\n",
      "percision:\n",
      "[0.9887745  0.97797271 0.94961148 0.94851391 0.95621084 0.95964018\n",
      " 0.96346455 0.89883181 0.92710377 0.93161454]\n",
      "recall:\n",
      "[0.94906861 0.98404168 0.92278633 0.96963465 0.96406472 0.9344968\n",
      " 0.95746789 0.95159531 0.95052532 0.91617844]\n"
     ]
    }
   ],
   "source": [
    "test()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader((dataset_dic['MNIST_linear_unbalanced_1']),batch_size=batch_size_train, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('./data', train=False, download=False,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)\n",
    "\n",
    "network = Net()\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)\n",
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/inf.ed.ac.uk/user/s16/s1636732/miniconda3/envs/mlp/lib/python3.7/site-packages/ipykernel_launcher.py:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 2.3067, Accuracy: 527/10000 (5%)\n",
      "\n",
      "[[   0  149    0    0    0    0  527  304    0    0]\n",
      " [   0   16    0    0    0    0 1086   33    0    0]\n",
      " [   0   51    0    0    0    0  874  107    0    0]\n",
      " [   0   29    0    0    0    0  896   85    0    0]\n",
      " [   0  148    0    0    0    0  754   80    0    0]\n",
      " [   0  101    0    0    0    0  587  204    0    0]\n",
      " [   0  455    0    0    0    0  453   50    0    0]\n",
      " [   0   36    0    0    0    0  934   58    0    0]\n",
      " [   0  161    0    0    0    0  769   44    0    0]\n",
      " [   0  201    0    0    0    0  750   58    0    0]]\n",
      "percision:\n",
      "[0.         0.0140969  0.         0.         0.         0.\n",
      " 0.47285963 0.05642018 0.         0.        ]\n",
      "recall:\n",
      "[0.         0.01187824 0.         0.         0.         0.\n",
      " 0.0593709  0.05669594 0.         0.        ]\n",
      "Train Epoch: 1 [0/27500 (0%)]\tLoss: 2.315684\n",
      "Train Epoch: 1 [3200/27500 (12%)]\tLoss: 2.106379\n",
      "Train Epoch: 1 [6400/27500 (23%)]\tLoss: 1.793035\n",
      "Train Epoch: 1 [9600/27500 (35%)]\tLoss: 1.259861\n",
      "Train Epoch: 1 [12800/27500 (47%)]\tLoss: 1.053994\n",
      "Train Epoch: 1 [16000/27500 (58%)]\tLoss: 1.191864\n",
      "Train Epoch: 1 [19200/27500 (70%)]\tLoss: 0.720047\n",
      "Train Epoch: 1 [22400/27500 (81%)]\tLoss: 0.633448\n",
      "Train Epoch: 1 [25600/27500 (93%)]\tLoss: 0.772933\n",
      "\n",
      "Test set: Avg. loss: 0.4917, Accuracy: 8385/10000 (83%)\n",
      "\n",
      "[[ 733    0    7   21    3  157   44    3    7    5]\n",
      " [   0 1109   14    4    0    0    3    0    4    1]\n",
      " [   3    5  940    8   11    4   22   24    3   12]\n",
      " [   0    1   18  934    0   24    1   14    2   16]\n",
      " [   0    1    3    0  659    1   26    1    0  291]\n",
      " [   5    5    5   54   22  762   17    3    2   17]\n",
      " [   2    5    4    2    4   19  920    1    0    1]\n",
      " [   0   15   31    3    0    1    0  879    1   98]\n",
      " [   0   32   30   93   23   88   31   21  488  168]\n",
      " [   1    7    1    8    9   12    1    9    0  961]]\n",
      "percision:\n",
      "[0.74795842 0.97709165 0.91085183 0.92475156 0.67107875 0.85425913\n",
      " 0.96033303 0.85505753 0.50102618 0.9524272 ]\n",
      "recall:\n",
      "[0.98521373 0.93982971 0.89268671 0.82874816 0.90150355 0.71348248\n",
      " 0.86384895 0.92041788 0.96252276 0.61210152]\n",
      "Train Epoch: 2 [0/27500 (0%)]\tLoss: 0.708402\n",
      "Train Epoch: 2 [3200/27500 (12%)]\tLoss: 0.484350\n",
      "Train Epoch: 2 [6400/27500 (23%)]\tLoss: 0.558779\n",
      "Train Epoch: 2 [9600/27500 (35%)]\tLoss: 0.407430\n",
      "Train Epoch: 2 [12800/27500 (47%)]\tLoss: 0.485629\n",
      "Train Epoch: 2 [16000/27500 (58%)]\tLoss: 0.461453\n",
      "Train Epoch: 2 [19200/27500 (70%)]\tLoss: 0.611960\n",
      "Train Epoch: 2 [22400/27500 (81%)]\tLoss: 0.339482\n",
      "Train Epoch: 2 [25600/27500 (93%)]\tLoss: 0.702438\n",
      "\n",
      "Test set: Avg. loss: 0.3084, Accuracy: 9089/10000 (90%)\n",
      "\n",
      "[[ 878    0    6    9    0    6   75    1    3    2]\n",
      " [   0 1126    4    2    0    0    3    0    0    0]\n",
      " [   3    8  982    7    5    3   12    8    3    1]\n",
      " [   0    1   20  961    1   10    0    9    0    8]\n",
      " [   0    4    3    1  869    0   52    0    1   52]\n",
      " [   4    4    2   47   10  796   24    1    2    2]\n",
      " [   4    4    1    0    1    5  943    0    0    0]\n",
      " [   0   22   44    4    2    0    1  891    0   64]\n",
      " [   3   50   34   38   16   33   52    9  690   49]\n",
      " [   2    8    2    8   11   13    5    6    1  953]]\n",
      "percision:\n",
      "[0.89591745 0.99206961 0.95154947 0.95148421 0.88492782 0.89237568\n",
      " 0.98434135 0.86673067 0.70841816 0.94449857]\n",
      "recall:\n",
      "[0.98210181 0.91768466 0.89435256 0.89229258 0.94972574 0.91916753\n",
      " 0.80805415 0.9632422  0.98571288 0.84261641]\n",
      "Train Epoch: 3 [0/27500 (0%)]\tLoss: 0.337539\n",
      "Train Epoch: 3 [3200/27500 (12%)]\tLoss: 0.508347\n",
      "Train Epoch: 3 [6400/27500 (23%)]\tLoss: 0.525847\n",
      "Train Epoch: 3 [9600/27500 (35%)]\tLoss: 0.591238\n",
      "Train Epoch: 3 [12800/27500 (47%)]\tLoss: 0.523057\n",
      "Train Epoch: 3 [16000/27500 (58%)]\tLoss: 0.498519\n",
      "Train Epoch: 3 [19200/27500 (70%)]\tLoss: 0.330741\n",
      "Train Epoch: 3 [22400/27500 (81%)]\tLoss: 0.491974\n",
      "Train Epoch: 3 [25600/27500 (93%)]\tLoss: 0.423995\n",
      "\n",
      "Test set: Avg. loss: 0.2145, Accuracy: 9316/10000 (93%)\n",
      "\n",
      "[[ 910    0    2    0    0    6   55    1    3    3]\n",
      " [   0 1125    4    2    0    0    4    0    0    0]\n",
      " [   4    5  983    8    2    2    7   15    4    2]\n",
      " [   0    0   16  968    0    5    0   10    4    7]\n",
      " [   0    3    3    1  854    0   38    0    2   81]\n",
      " [   3    1    2   36    1  830   12    2    1    4]\n",
      " [   4    2    0    0    1    6  945    0    0    0]\n",
      " [   1   10   25    5    1    0    0  960    0   26]\n",
      " [   4   18   35   23    8   30   36   10  773   37]\n",
      " [   2    8    0    6    4   12    2    6    1  968]]\n",
      "percision:\n",
      "[0.92857048 0.99118855 0.95251846 0.95841489 0.86965288 0.93049223\n",
      " 0.98642903 0.93385123 0.79363368 0.95936476]\n",
      "recall:\n",
      "[0.98060239 0.95989679 0.91869073 0.92278272 0.98048108 0.93153655\n",
      " 0.85987183 0.95617435 0.98096322 0.85815527]\n"
     ]
    }
   ],
   "source": [
    "test()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4500"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.array(dataset_dic['MNIST_linear_unbalanced_1'].targets)== 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader((dataset_dic['MNIST_expo_unbalance']),batch_size=batch_size_train, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('./data', train=False, download=False,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)\n",
    "\n",
    "network = Net()\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)\n",
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/inf.ed.ac.uk/user/s16/s1636732/miniconda3/envs/mlp/lib/python3.7/site-packages/ipykernel_launcher.py:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 2.3109, Accuracy: 741/10000 (7%)\n",
      "\n",
      "[[  0  90   0 364   0 524   0   0   2   0]\n",
      " [  0 256   0   9   0 870   0   0   0   0]\n",
      " [  0  85   0   6   0 940   0   0   1   0]\n",
      " [  0 242   0  38   0 717   0   0  13   0]\n",
      " [  0 559   0  23   3 387   0   0  10   0]\n",
      " [  0 192   0 248   0 441   0   0  11   0]\n",
      " [  0 193   0  78   0 679   0   0   8   0]\n",
      " [  0 607   0  11   0 404   0   0   6   0]\n",
      " [  0  66   0  12   0 893   0   0   3   0]\n",
      " [  0 448   0  23   3 515   0   0  20   0]]\n",
      "percision:\n",
      "[0.         0.22555046 0.         0.03762373 0.00305499 0.49439406\n",
      " 0.         0.         0.00308008 0.        ]\n",
      "recall:\n",
      "[0.         0.09349887 0.         0.04679797 0.49991668 0.06923076\n",
      " 0.         0.         0.04053999 0.        ]\n",
      "Train Epoch: 1 [0/27500 (0%)]\tLoss: 2.370296\n",
      "Train Epoch: 1 [3200/27500 (12%)]\tLoss: 2.194833\n",
      "Train Epoch: 1 [6400/27500 (23%)]\tLoss: 1.805672\n",
      "Train Epoch: 1 [9600/27500 (35%)]\tLoss: 1.272083\n",
      "Train Epoch: 1 [12800/27500 (47%)]\tLoss: 1.134211\n",
      "Train Epoch: 1 [16000/27500 (58%)]\tLoss: 0.724285\n",
      "Train Epoch: 1 [19200/27500 (70%)]\tLoss: 0.874142\n",
      "Train Epoch: 1 [22400/27500 (81%)]\tLoss: 0.754424\n",
      "Train Epoch: 1 [25600/27500 (93%)]\tLoss: 0.525391\n",
      "\n",
      "Test set: Avg. loss: 0.4097, Accuracy: 8841/10000 (88%)\n",
      "\n",
      "[[ 906    0    9    9    0   10   37    2    5    2]\n",
      " [   0 1120    4    4    0    0    3    0    3    1]\n",
      " [   9    3  964   17   10    0   19    7    3    0]\n",
      " [   2    2   31  948    0   14    0    8    1    4]\n",
      " [   0    1    5    0  773    0   51    0    3  149]\n",
      " [   6    4   10   82    5  740   13    3   22    7]\n",
      " [   9    4    6    1    2    8  927    0    1    0]\n",
      " [   2   28   27    9    1    1    0  882    1   77]\n",
      " [   5   20   13  110   15   57   28   12  677   37]\n",
      " [   2    7    9   14   43   15    4    7    4  904]]\n",
      "percision:\n",
      "[0.92448885 0.98678327 0.93410762 0.93861293 0.78716824 0.82959548\n",
      " 0.96763991 0.85797582 0.69507115 0.89593568]\n",
      "recall:\n",
      "[0.9628045  0.94196725 0.89424778 0.79396918 0.91048185 0.87573861\n",
      " 0.85674597 0.95765368 0.94027647 0.76545236]\n",
      "Train Epoch: 2 [0/27500 (0%)]\tLoss: 0.516058\n",
      "Train Epoch: 2 [3200/27500 (12%)]\tLoss: 0.596932\n",
      "Train Epoch: 2 [6400/27500 (23%)]\tLoss: 0.806026\n",
      "Train Epoch: 2 [9600/27500 (35%)]\tLoss: 0.655909\n",
      "Train Epoch: 2 [12800/27500 (47%)]\tLoss: 0.699592\n",
      "Train Epoch: 2 [16000/27500 (58%)]\tLoss: 0.500642\n",
      "Train Epoch: 2 [19200/27500 (70%)]\tLoss: 0.490058\n",
      "Train Epoch: 2 [22400/27500 (81%)]\tLoss: 0.557591\n",
      "Train Epoch: 2 [25600/27500 (93%)]\tLoss: 0.375659\n",
      "\n",
      "Test set: Avg. loss: 0.2564, Accuracy: 9236/10000 (92%)\n",
      "\n",
      "[[ 938    1    2    0    0    4   28    2    3    2]\n",
      " [   0 1121    4    3    0    0    4    0    3    0]\n",
      " [   8    3  969   12    6    1    8   18    2    5]\n",
      " [   2    0   21  925    0   29    0   20    2   11]\n",
      " [   0    1    2    0  862    0   22    0    2   93]\n",
      " [   8    2    2   11    0  845   10    5    3    6]\n",
      " [   8    3    2    0    4    6  935    0    0    0]\n",
      " [   1    6   18    1    0    0    0  962    1   39]\n",
      " [   6   19   18   25   11   56   26   31  726   56]\n",
      " [   5    5    0    4   15   14    2   11    0  953]]\n",
      "percision:\n",
      "[0.95714188 0.98766433 0.93895258 0.91584068 0.87779951 0.94730836\n",
      " 0.97599063 0.93579676 0.74537911 0.94449857]\n",
      "recall:\n",
      "[0.96106459 0.96554611 0.93352511 0.94291443 0.95990984 0.88481583\n",
      " 0.90338077 0.917063   0.97843534 0.81802505]\n",
      "Train Epoch: 3 [0/27500 (0%)]\tLoss: 0.507594\n",
      "Train Epoch: 3 [3200/27500 (12%)]\tLoss: 0.581399\n",
      "Train Epoch: 3 [6400/27500 (23%)]\tLoss: 0.270550\n",
      "Train Epoch: 3 [9600/27500 (35%)]\tLoss: 0.452969\n",
      "Train Epoch: 3 [12800/27500 (47%)]\tLoss: 0.502727\n",
      "Train Epoch: 3 [16000/27500 (58%)]\tLoss: 0.511882\n",
      "Train Epoch: 3 [19200/27500 (70%)]\tLoss: 0.382360\n",
      "Train Epoch: 3 [22400/27500 (81%)]\tLoss: 0.334624\n",
      "Train Epoch: 3 [25600/27500 (93%)]\tLoss: 0.358722\n",
      "\n",
      "Test set: Avg. loss: 0.1750, Accuracy: 9467/10000 (94%)\n",
      "\n",
      "[[ 958    0    2    0    0    1   14    1    4    0]\n",
      " [   0 1125    4    2    0    0    2    0    2    0]\n",
      " [   9    1  987   11    5    0    5    9    4    1]\n",
      " [   1    0   24  952    0   19    0   10    4    0]\n",
      " [   0    1    2    0  923    0   22    0    3   31]\n",
      " [  12    2    0   10    0  850   11    2    3    2]\n",
      " [  11    3    2    0    4    1  937    0    0    0]\n",
      " [   2    7   25    8    1    1    0  956    1   27]\n",
      " [  14   11   13   14    9   16   18   15  833   31]\n",
      " [   6    5    0    4   23    9    2   11    3  946]]\n",
      "percision:\n",
      "[0.97755002 0.99118855 0.95639442 0.94257332 0.93991758 0.95291373\n",
      " 0.97807831 0.92996018 0.85523526 0.93756101]\n",
      "recall:\n",
      "[0.94570489 0.97402513 0.93201045 0.951048   0.95647569 0.94760207\n",
      " 0.92680423 0.95219029 0.9719942  0.91136714]\n"
     ]
    }
   ],
   "source": [
    "test()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv1_bn = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv2_bn = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv3_bn = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.conv4_bn = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc1_bn= nn.BatchNorm1d(512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc2_bn= nn.BatchNorm1d(128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1_bn(self.conv1(x)), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_bn(self.conv2(x)), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv3_bn(self.conv3(x)), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv4_bn(self.conv4(x)), 2))\n",
    "        x = x.view(-1, 1024)\n",
    "        x = F.relu(self.fc1_bn(self.fc1(x)))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.fc2_bn(self.fc2(x)))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader((dataset_dic['CIFAR10_balanced']),batch_size=batch_size_train, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.CIFAR10(root='./data', train=False,download=True, transform=transform),\n",
    "  batch_size=batch_size_test, shuffle=True)\n",
    "\n",
    "network = Net()\n",
    "optimizer = optim.Adam(network.parameters())\n",
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/inf.ed.ac.uk/user/s16/s1636732/miniconda3/envs/mlp/lib/python3.7/site-packages/ipykernel_launcher.py:33: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 2.3038, Accuracy: 1001/10000 (10%)\n",
      "\n",
      "[[   0    0    2    0    0    0    0    0  998    0]\n",
      " [   0    0    0    0    0    0    0    0 1000    0]\n",
      " [   0    0    1    0    0    0    0    0  999    0]\n",
      " [   0    0    0    0    0    0    0    0 1000    0]\n",
      " [   0    0    0    0    0    0    0    0 1000    0]\n",
      " [   0    0    0    0    0    0    0    0 1000    0]\n",
      " [   0    0    1    0    0    0    0    0  999    0]\n",
      " [   0    0    0    0    0    0    0    0 1000    0]\n",
      " [   0    0    0    0    0    0    0    0 1000    0]\n",
      " [   0    0    0    0    0    0    0    0 1000    0]]\n",
      "percision:\n",
      "[0.00000e+00 0.00000e+00 9.99999e-04 0.00000e+00 0.00000e+00 0.00000e+00\n",
      " 0.00000e+00 0.00000e+00 9.99999e-01 0.00000e+00]\n",
      "recall:\n",
      "[0.         0.         0.24993752 0.         0.         0.\n",
      " 0.         0.         0.10004001 0.        ]\n",
      "Train Epoch: 1 [0/27500 (0%)]\tLoss: 2.367719\n",
      "Train Epoch: 1 [3200/27500 (12%)]\tLoss: 1.823797\n",
      "Train Epoch: 1 [6400/27500 (23%)]\tLoss: 1.507494\n",
      "Train Epoch: 1 [9600/27500 (35%)]\tLoss: 1.402277\n",
      "Train Epoch: 1 [12800/27500 (47%)]\tLoss: 1.253679\n",
      "Train Epoch: 1 [16000/27500 (58%)]\tLoss: 1.359339\n",
      "Train Epoch: 1 [19200/27500 (70%)]\tLoss: 1.154181\n",
      "Train Epoch: 1 [22400/27500 (81%)]\tLoss: 1.008547\n",
      "Train Epoch: 1 [25600/27500 (93%)]\tLoss: 1.228357\n",
      "\n",
      "Test set: Avg. loss: 1.1813, Accuracy: 5762/10000 (57%)\n",
      "\n",
      "[[743  28  75  18  30   4  30   6  42  24]\n",
      " [ 32 791   5   2  23   4  63   2  10  68]\n",
      " [ 94   3 410  23 232  63 155  12   5   3]\n",
      " [ 22  18 108 220  92 221 303   4   7   5]\n",
      " [ 35   4  51  22 651  39 167  24   5   2]\n",
      " [ 12   6 104 128 103 486 141  13   5   2]\n",
      " [  7   6  29  34  58  11 853   1   1   0]\n",
      " [ 19   4  69  23 241 146  52 427   3  16]\n",
      " [213  80  29  20  29   4  30   2 561  32]\n",
      " [ 46 158  18  16  17   7  78   6  34 620]]\n",
      "percision:\n",
      "[0.74299926 0.79099921 0.40999959 0.21999978 0.65099935 0.48599951\n",
      " 0.85299915 0.42699957 0.56099944 0.61999938]\n",
      "recall:\n",
      "[0.60752199 0.72040007 0.45656965 0.43478175 0.44105661 0.49340051\n",
      " 0.45566215 0.8591532  0.83357974 0.80310777]\n",
      "Train Epoch: 2 [0/27500 (0%)]\tLoss: 1.244830\n",
      "Train Epoch: 2 [3200/27500 (12%)]\tLoss: 0.915467\n",
      "Train Epoch: 2 [6400/27500 (23%)]\tLoss: 1.310090\n",
      "Train Epoch: 2 [9600/27500 (35%)]\tLoss: 0.913157\n",
      "Train Epoch: 2 [12800/27500 (47%)]\tLoss: 0.778579\n",
      "Train Epoch: 2 [16000/27500 (58%)]\tLoss: 0.969688\n",
      "Train Epoch: 2 [19200/27500 (70%)]\tLoss: 0.910219\n",
      "Train Epoch: 2 [22400/27500 (81%)]\tLoss: 1.214468\n",
      "Train Epoch: 2 [25600/27500 (93%)]\tLoss: 0.848832\n",
      "\n",
      "Test set: Avg. loss: 0.9435, Accuracy: 6679/10000 (66%)\n",
      "\n",
      "[[627  38  49  42  13  13   6  16  97  99]\n",
      " [  4 798   0   8   1  12   9   5  13 150]\n",
      " [ 69   8 487 125  36 112  63  59  23  18]\n",
      " [  8   8  43 568  20 227  47  41  21  17]\n",
      " [ 19   3 119 109 407  67  61 191  21   3]\n",
      " [  7   5  33 224  15 612  18  61  15  10]\n",
      " [  6   5  42 128  24  38 725  18   9   5]\n",
      " [  8   2  12  57   9  85   1 791   6  29]\n",
      " [ 39  58   7  18   3   9   1   7 816  42]\n",
      " [  5  69   3  25   2   5  10   9  24 848]]\n",
      "percision:\n",
      "[0.62699937 0.7979992  0.48699951 0.56799943 0.40699959 0.61199939\n",
      " 0.72499928 0.79099921 0.81599918 0.84799915]\n",
      "recall:\n",
      "[0.79166567 0.80281609 0.61257785 0.43558249 0.76792308 0.51864363\n",
      " 0.77045614 0.66026656 0.7808605  0.69451213]\n",
      "Train Epoch: 3 [0/27500 (0%)]\tLoss: 0.742438\n",
      "Train Epoch: 3 [3200/27500 (12%)]\tLoss: 0.832030\n",
      "Train Epoch: 3 [6400/27500 (23%)]\tLoss: 0.788582\n",
      "Train Epoch: 3 [9600/27500 (35%)]\tLoss: 0.746731\n",
      "Train Epoch: 3 [12800/27500 (47%)]\tLoss: 0.907414\n",
      "Train Epoch: 3 [16000/27500 (58%)]\tLoss: 1.042915\n",
      "Train Epoch: 3 [19200/27500 (70%)]\tLoss: 1.075553\n",
      "Train Epoch: 3 [22400/27500 (81%)]\tLoss: 0.736534\n",
      "Train Epoch: 3 [25600/27500 (93%)]\tLoss: 0.763271\n",
      "\n",
      "Test set: Avg. loss: 0.8331, Accuracy: 7067/10000 (70%)\n",
      "\n",
      "[[692   8  84  25   8  11   9  14 115  34]\n",
      " [ 32 732   9   9   5   3  31  13  35 131]\n",
      " [ 41   1 672  33  71  49  73  32  26   2]\n",
      " [ 14   1 132 559  56 115  72  34  12   5]\n",
      " [  8   0 138  65 654  15  61  45  14   0]\n",
      " [ 11   1 106 219  57 523  30  46   5   2]\n",
      " [  6   1  51  61  34   8 830   0   9   0]\n",
      " [  7   2  60  41  70  40   5 772   2   1]\n",
      " [ 42  27  20  14   2   8   5   8 858  16]\n",
      " [ 38  32  14  42   8   5  10  34  42 775]]\n",
      "percision:\n",
      "[0.69199931 0.73199927 0.67199933 0.55899944 0.65399935 0.52299948\n",
      " 0.82999917 0.77199923 0.85799914 0.77499923]\n",
      "recall:\n",
      "[0.77665457 0.90931564 0.52255014 0.52340775 0.6777195  0.67310081\n",
      " 0.7371219  0.77354632 0.76744117 0.8022766 ]\n",
      "Train Epoch: 4 [0/27500 (0%)]\tLoss: 0.645110\n",
      "Train Epoch: 4 [3200/27500 (12%)]\tLoss: 0.882612\n",
      "Train Epoch: 4 [6400/27500 (23%)]\tLoss: 0.884326\n",
      "Train Epoch: 4 [9600/27500 (35%)]\tLoss: 0.846571\n",
      "Train Epoch: 4 [12800/27500 (47%)]\tLoss: 0.814519\n",
      "Train Epoch: 4 [16000/27500 (58%)]\tLoss: 0.572727\n",
      "Train Epoch: 4 [19200/27500 (70%)]\tLoss: 0.626461\n",
      "Train Epoch: 4 [22400/27500 (81%)]\tLoss: 0.662966\n",
      "Train Epoch: 4 [25600/27500 (93%)]\tLoss: 0.680359\n",
      "\n",
      "Test set: Avg. loss: 0.8176, Accuracy: 7214/10000 (72%)\n",
      "\n",
      "[[829  16  24   9  20   4   5  11  20  62]\n",
      " [ 15 850   1   2   0   0   2   2  11 117]\n",
      " [ 99   8 526  44 145  53  31  44  15  35]\n",
      " [ 34  11  65 496 121 126  39  39  15  54]\n",
      " [ 33   4  21  31 805  13   6  74   8   5]\n",
      " [ 20   8  45 136  86 592  14  62   8  29]\n",
      " [ 10  15  36  65 118  19 692  14   8  23]\n",
      " [ 21   3  18  27  66  40   5 775   2  43]\n",
      " [126  34   8   7   7   3   3   0 739  73]\n",
      " [ 24  43   3   5   4   0   2   4   5 910]]\n",
      "percision:\n",
      "[0.82899917 0.84999915 0.52599947 0.4959995  0.8049992  0.59199941\n",
      " 0.69199931 0.77499923 0.73899926 0.90999909]\n",
      "recall:\n",
      "[0.68455765 0.85685397 0.70414899 0.60340559 0.58673427 0.69646977\n",
      " 0.86608152 0.75609682 0.88928894 0.67357463]\n",
      "Train Epoch: 5 [0/27500 (0%)]\tLoss: 0.655842\n",
      "Train Epoch: 5 [3200/27500 (12%)]\tLoss: 0.607578\n",
      "Train Epoch: 5 [6400/27500 (23%)]\tLoss: 0.610642\n",
      "Train Epoch: 5 [9600/27500 (35%)]\tLoss: 0.644327\n",
      "Train Epoch: 5 [12800/27500 (47%)]\tLoss: 0.662599\n",
      "Train Epoch: 5 [16000/27500 (58%)]\tLoss: 0.492298\n",
      "Train Epoch: 5 [19200/27500 (70%)]\tLoss: 0.713719\n",
      "Train Epoch: 5 [22400/27500 (81%)]\tLoss: 0.820282\n",
      "Train Epoch: 5 [25600/27500 (93%)]\tLoss: 0.654085\n",
      "\n",
      "Test set: Avg. loss: 0.8006, Accuracy: 7226/10000 (72%)\n",
      "\n",
      "[[628  24  22  57  52   4   6  34  80  93]\n",
      " [  6 837   2   6   4   0   3  11  10 121]\n",
      " [ 49   6 445 133 147  53  62  80  12  13]\n",
      " [  3   4  22 695  79  65  40  63   6  23]\n",
      " [  3   1  14  91 730  17  31 105   6   2]\n",
      " [  4   2  10 305  53 489  16 107   5   9]\n",
      " [  4   8  11  92  49  11 803  14   3   5]\n",
      " [  4   2   4  36  40  22   1 881   1   9]\n",
      " [ 23  30   5  19  10   1   6  11 834  61]\n",
      " [  8  54   1  14   8   1   2  21   7 884]]\n",
      "percision:\n",
      "[0.62799937 0.83699916 0.44499956 0.69499931 0.72999927 0.48899951\n",
      " 0.8029992  0.88099912 0.83399917 0.88399912]\n",
      "recall:\n",
      "[0.85792233 0.86466853 0.83022233 0.47997204 0.62286636 0.73755545\n",
      " 0.8278342  0.66390304 0.86514433 0.72458957]\n",
      "Train Epoch: 6 [0/27500 (0%)]\tLoss: 0.339268\n",
      "Train Epoch: 6 [3200/27500 (12%)]\tLoss: 0.648649\n",
      "Train Epoch: 6 [6400/27500 (23%)]\tLoss: 0.427424\n",
      "Train Epoch: 6 [9600/27500 (35%)]\tLoss: 0.466042\n",
      "Train Epoch: 6 [12800/27500 (47%)]\tLoss: 0.383430\n",
      "Train Epoch: 6 [16000/27500 (58%)]\tLoss: 0.609821\n",
      "Train Epoch: 6 [19200/27500 (70%)]\tLoss: 0.248637\n",
      "Train Epoch: 6 [22400/27500 (81%)]\tLoss: 0.757959\n",
      "Train Epoch: 6 [25600/27500 (93%)]\tLoss: 0.461919\n",
      "\n",
      "Test set: Avg. loss: 0.7992, Accuracy: 7248/10000 (72%)\n",
      "\n",
      "[[725  14  27  71  12   3   3  15  97  33]\n",
      " [  9 877   1   8   0   2   3   4  34  62]\n",
      " [ 57   6 464 188  85  68  50  39  33  10]\n",
      " [  8   4  18 741  36  81  46  33  20  13]\n",
      " [ 13   1  14 133 634  55  20 114  14   2]\n",
      " [  5   3   8 332  23 538  19  60  10   2]\n",
      " [  5   7  19 115  49  27 752  12   8   6]\n",
      " [  9   3   7  81  25  43   2 821   2   7]\n",
      " [ 36  24   0  31   4   1   1   2 877  24]\n",
      " [ 27  81   2  16   0   2   4  18  31 819]]\n",
      "percision:\n",
      "[0.72499928 0.87699912 0.46399954 0.74099926 0.63399937 0.53799946\n",
      " 0.75199925 0.82099918 0.87699912 0.81899918]\n",
      "recall:\n",
      "[0.81096106 0.85980308 0.82856995 0.43181793 0.73041391 0.65609676\n",
      " 0.83555463 0.73434639 0.77886254 0.83742246]\n",
      "Train Epoch: 7 [0/27500 (0%)]\tLoss: 0.475711\n",
      "Train Epoch: 7 [3200/27500 (12%)]\tLoss: 0.485218\n",
      "Train Epoch: 7 [6400/27500 (23%)]\tLoss: 0.304615\n",
      "Train Epoch: 7 [9600/27500 (35%)]\tLoss: 0.615668\n",
      "Train Epoch: 7 [12800/27500 (47%)]\tLoss: 0.460261\n",
      "Train Epoch: 7 [16000/27500 (58%)]\tLoss: 0.427510\n",
      "Train Epoch: 7 [19200/27500 (70%)]\tLoss: 0.256685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [22400/27500 (81%)]\tLoss: 0.570581\n",
      "Train Epoch: 7 [25600/27500 (93%)]\tLoss: 0.694406\n",
      "\n",
      "Test set: Avg. loss: 0.8140, Accuracy: 7321/10000 (73%)\n",
      "\n",
      "[[816  13  17  19  15   1   0  12  83  24]\n",
      " [ 13 871   5   4   2   1   2   2  32  68]\n",
      " [111   8 632  49  87  17  16  47  29   4]\n",
      " [ 35   8  90 556  95  80  24  55  34  23]\n",
      " [ 29   3  49  44 776  12   4  61  21   1]\n",
      " [ 19   4  74 211  67 489   8  99  19  10]\n",
      " [ 20   6  96  93 106  10 626  11  22  10]\n",
      " [ 20   3  21  30  54  18   0 837   9   8]\n",
      " [ 41  17   5   6   7   1   1   3 904  15]\n",
      " [ 48  68   5   6   5   0   1  14  39 814]]\n",
      "percision:\n",
      "[0.81599918 0.87099913 0.63199937 0.55599944 0.77599922 0.48899951\n",
      " 0.62599937 0.83699916 0.9039991  0.81399919]\n",
      "recall:\n",
      "[0.70833272 0.870129   0.63581425 0.54616842 0.6392087  0.77742325\n",
      " 0.91788722 0.7335664  0.75838863 0.83316189]\n",
      "Train Epoch: 8 [0/27500 (0%)]\tLoss: 0.360334\n",
      "Train Epoch: 8 [3200/27500 (12%)]\tLoss: 0.290642\n",
      "Train Epoch: 8 [6400/27500 (23%)]\tLoss: 0.333529\n",
      "Train Epoch: 8 [9600/27500 (35%)]\tLoss: 0.342201\n",
      "Train Epoch: 8 [12800/27500 (47%)]\tLoss: 0.495986\n",
      "Train Epoch: 8 [16000/27500 (58%)]\tLoss: 0.206922\n",
      "Train Epoch: 8 [19200/27500 (70%)]\tLoss: 0.411034\n",
      "Train Epoch: 8 [22400/27500 (81%)]\tLoss: 0.529498\n",
      "Train Epoch: 8 [25600/27500 (93%)]\tLoss: 0.409895\n",
      "\n",
      "Test set: Avg. loss: 0.8396, Accuracy: 7396/10000 (73%)\n",
      "\n",
      "[[739  12  40  14  23  10   6  10 100  46]\n",
      " [ 16 784   3   2   2   4   0   3  34 152]\n",
      " [ 60   2 572  37 147  84  31  37  20  10]\n",
      " [ 13   6  48 389 109 284  44  49  22  36]\n",
      " [ 10   2  25  12 832  31   5  66  10   7]\n",
      " [  8   2  22  64  81 732  10  58  13  10]\n",
      " [  9   6  30  41 100  44 742   6   8  14]\n",
      " [  7   2  20  12  50  55   1 840   1  12]\n",
      " [ 35  10  11   7  12   5   2   7 876  35]\n",
      " [ 19  39   3   1   7   4   4  13  20 890]]\n",
      "percision:\n",
      "[0.73899926 0.78399922 0.57199943 0.38899961 0.83199917 0.73199927\n",
      " 0.74199926 0.83999916 0.87599912 0.88999911]\n",
      "recall:\n",
      "[0.80676768 0.90635733 0.73901713 0.67184685 0.61041775 0.58419746\n",
      " 0.87810547 0.77134915 0.79347754 0.73432283]\n",
      "Train Epoch: 9 [0/27500 (0%)]\tLoss: 0.295232\n",
      "Train Epoch: 9 [3200/27500 (12%)]\tLoss: 0.329823\n",
      "Train Epoch: 9 [6400/27500 (23%)]\tLoss: 0.255739\n",
      "Train Epoch: 9 [9600/27500 (35%)]\tLoss: 0.170896\n",
      "Train Epoch: 9 [12800/27500 (47%)]\tLoss: 0.446920\n",
      "Train Epoch: 9 [16000/27500 (58%)]\tLoss: 0.324089\n",
      "Train Epoch: 9 [19200/27500 (70%)]\tLoss: 0.345762\n",
      "Train Epoch: 9 [22400/27500 (81%)]\tLoss: 0.255155\n",
      "Train Epoch: 9 [25600/27500 (93%)]\tLoss: 0.448352\n",
      "\n",
      "Test set: Avg. loss: 0.8153, Accuracy: 7563/10000 (75%)\n",
      "\n",
      "[[792  22  69   9  17   8  15  21  36  11]\n",
      " [ 18 884   7   6   6   4   4  13  24  34]\n",
      " [ 38   2 708  20  85  52  46  41   6   2]\n",
      " [ 11   2  97 427  94 188  93  76   9   3]\n",
      " [ 14   0  54  16 777  34  19  79   6   1]\n",
      " [  4   0  61  73  51 704  25  77   4   1]\n",
      " [  4   3  40  21  54  12 847  15   3   1]\n",
      " [ 10   1  29   8  34  56   1 860   1   0]\n",
      " [ 66  22  21  11  18   4   7  13 831   7]\n",
      " [ 45 103   9   7  11  11  15  43  23 733]]\n",
      "percision:\n",
      "[0.79199921 0.88399912 0.70799929 0.42699957 0.77699922 0.7039993\n",
      " 0.84699915 0.85999914 0.83099917 0.73299927]\n",
      "recall:\n",
      "[0.79041837 0.85081728 0.64657475 0.71404563 0.67741876 0.65610377\n",
      " 0.7901112  0.69466826 0.88122918 0.92433679]\n",
      "Train Epoch: 10 [0/27500 (0%)]\tLoss: 0.145421\n",
      "Train Epoch: 10 [3200/27500 (12%)]\tLoss: 0.152041\n",
      "Train Epoch: 10 [6400/27500 (23%)]\tLoss: 0.342830\n",
      "Train Epoch: 10 [9600/27500 (35%)]\tLoss: 0.248858\n",
      "Train Epoch: 10 [12800/27500 (47%)]\tLoss: 0.440458\n",
      "Train Epoch: 10 [16000/27500 (58%)]\tLoss: 0.110589\n",
      "Train Epoch: 10 [19200/27500 (70%)]\tLoss: 0.374812\n",
      "Train Epoch: 10 [22400/27500 (81%)]\tLoss: 0.361447\n",
      "Train Epoch: 10 [25600/27500 (93%)]\tLoss: 0.412476\n",
      "\n",
      "Test set: Avg. loss: 0.8514, Accuracy: 7491/10000 (74%)\n",
      "\n",
      "[[784  31  65  13  18   9   5   2  47  26]\n",
      " [  8 923   5   6   0   8   2   0  17  31]\n",
      " [ 48   3 730  41  67  50  33  11  12   5]\n",
      " [ 21   6  84 558  60 201  38  14   8  10]\n",
      " [ 18   0  75  55 726  65  31  15   9   6]\n",
      " [ 10   4  70 121  40 712  15  20   2   6]\n",
      " [  8   7  59  92  29  42 753   0   5   5]\n",
      " [ 23   7  53  31  77  92   3 696   4  14]\n",
      " [ 51  42  23   9  12   7   4   3 831  18]\n",
      " [ 23 130   8  12   3  11   9   6  20 778]]\n",
      "percision:\n",
      "[0.78399922 0.92299908 0.72999927 0.55799944 0.72599927 0.71199929\n",
      " 0.75299925 0.6959993  0.83099917 0.77799922]\n",
      "recall:\n",
      "[0.7887316  0.80051969 0.62286636 0.5948821  0.70348769 0.59481989\n",
      " 0.84322414 0.90743037 0.87015616 0.86540504]\n",
      "Train Epoch: 11 [0/27500 (0%)]\tLoss: 0.310780\n",
      "Train Epoch: 11 [3200/27500 (12%)]\tLoss: 0.190457\n",
      "Train Epoch: 11 [6400/27500 (23%)]\tLoss: 0.299258\n",
      "Train Epoch: 11 [9600/27500 (35%)]\tLoss: 0.118738\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-b4d077c6cdb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-20df77d4b376>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mlp/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mlp/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mlp/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mlp/lib/python3.7/site-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mtuple\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mwhere\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mindex\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32mclass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;31m# doing this so that it is consistent with all other datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "test()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader((dataset_dic['CIFAR10_linear_unbalanced_1']),batch_size=batch_size_train, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.CIFAR10(root='./data', train=False,download=True, transform=transform),\n",
    "  batch_size=batch_size_test, shuffle=True)\n",
    "\n",
    "network = Net()\n",
    "optimizer = optim.Adam(network.parameters())\n",
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/inf.ed.ac.uk/user/s16/s1636732/miniconda3/envs/mlp/lib/python3.7/site-packages/ipykernel_launcher.py:33: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 2.3032, Accuracy: 1000/10000 (10%)\n",
      "\n",
      "[[   0    0 1000    0    0    0    0    0    0    0]\n",
      " [   0    0 1000    0    0    0    0    0    0    0]\n",
      " [   0    0 1000    0    0    0    0    0    0    0]\n",
      " [   0    0 1000    0    0    0    0    0    0    0]\n",
      " [   0    0 1000    0    0    0    0    0    0    0]\n",
      " [   0    0 1000    0    0    0    0    0    0    0]\n",
      " [   0    0 1000    0    0    0    0    0    0    0]\n",
      " [   0    0 1000    0    0    0    0    0    0    0]\n",
      " [   0    0 1000    0    0    0    0    0    0    0]\n",
      " [   0    0 1000    0    0    0    0    0    0    0]]\n",
      "percision:\n",
      "[0.       0.       0.999999 0.       0.       0.       0.       0.\n",
      " 0.       0.      ]\n",
      "recall:\n",
      "[0.         0.         0.09999999 0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n",
      "Train Epoch: 1 [0/27500 (0%)]\tLoss: 2.507617\n",
      "Train Epoch: 1 [3200/27500 (12%)]\tLoss: 1.515961\n",
      "Train Epoch: 1 [6400/27500 (23%)]\tLoss: 1.479474\n",
      "Train Epoch: 1 [9600/27500 (35%)]\tLoss: 1.235299\n",
      "Train Epoch: 1 [12800/27500 (47%)]\tLoss: 1.215361\n",
      "Train Epoch: 1 [16000/27500 (58%)]\tLoss: 1.099855\n",
      "Train Epoch: 1 [19200/27500 (70%)]\tLoss: 1.178817\n",
      "Train Epoch: 1 [22400/27500 (81%)]\tLoss: 1.161410\n",
      "Train Epoch: 1 [25600/27500 (93%)]\tLoss: 0.797144\n",
      "\n",
      "Test set: Avg. loss: 1.3929, Accuracy: 5069/10000 (50%)\n",
      "\n",
      "[[ 27 237 138  41   1  39   7   2 462  46]\n",
      " [  0 957   0   7   0   5   4   1   7  19]\n",
      " [  4  44 425 173   9 203  81   6  42  13]\n",
      " [  0  76  45 456   2 326  50   8  12  25]\n",
      " [  1  51 171 180 149 152 143 111  33   9]\n",
      " [  0  28  56 189   2 673  21  14   7  10]\n",
      " [  0  24  26 218   2  48 674   1   4   3]\n",
      " [  0  43  43  73   8 271  14 497  13  38]\n",
      " [  0 200  18  22   0  19   4   2 685  50]\n",
      " [  0 400   2  21   0   8  11   1  31 526]]\n",
      "percision:\n",
      "[0.02699997 0.95699904 0.42499958 0.45599954 0.14899985 0.67299933\n",
      " 0.67399933 0.4969995  0.68499932 0.52599947]\n",
      "recall:\n",
      "[0.84372363 0.46456288 0.45995621 0.33043454 0.8612667  0.38589427\n",
      " 0.66798745 0.77293814 0.52854897 0.7117717 ]\n",
      "Train Epoch: 2 [0/27500 (0%)]\tLoss: 0.845732\n",
      "Train Epoch: 2 [3200/27500 (12%)]\tLoss: 1.027211\n",
      "Train Epoch: 2 [6400/27500 (23%)]\tLoss: 0.994296\n",
      "Train Epoch: 2 [9600/27500 (35%)]\tLoss: 1.059453\n",
      "Train Epoch: 2 [12800/27500 (47%)]\tLoss: 1.076956\n",
      "Train Epoch: 2 [16000/27500 (58%)]\tLoss: 1.146446\n",
      "Train Epoch: 2 [19200/27500 (70%)]\tLoss: 0.823691\n",
      "Train Epoch: 2 [22400/27500 (81%)]\tLoss: 0.936269\n",
      "Train Epoch: 2 [25600/27500 (93%)]\tLoss: 0.975897\n",
      "\n",
      "Test set: Avg. loss: 1.0218, Accuracy: 6367/10000 (63%)\n",
      "\n",
      "[[217  59 173  19  37  13  23  61 299  99]\n",
      " [  0 879   0   2   2   2   5  12  19  79]\n",
      " [ 20  16 538  35  67 126  59 111  14  14]\n",
      " [  1  14  62 337  50 340  61 102  12  21]\n",
      " [  7   4 112  42 464  71  71 211  10   8]\n",
      " [  3   8  30  67  33 710  28 108   2  11]\n",
      " [  0  10  33  58  29  39 800  19   3   9]\n",
      " [  2   2  12  11  30  80   9 829   4  21]\n",
      " [ 26  67  19  15  13   4  11  22 766  57]\n",
      " [  0  93   5  11   5   5   4  17  33 827]]\n",
      "percision:\n",
      "[0.21699978 0.87899912 0.53799946 0.33699966 0.46399954 0.70999929\n",
      " 0.7999992  0.82899917 0.76599923 0.82699917]\n",
      "recall:\n",
      "[0.78622904 0.76302017 0.54674741 0.56448817 0.63561557 0.510791\n",
      " 0.74696476 0.55562965 0.65920769 0.72163986]\n",
      "Train Epoch: 3 [0/27500 (0%)]\tLoss: 0.762693\n",
      "Train Epoch: 3 [3200/27500 (12%)]\tLoss: 0.686612\n",
      "Train Epoch: 3 [6400/27500 (23%)]\tLoss: 0.744063\n",
      "Train Epoch: 3 [9600/27500 (35%)]\tLoss: 0.840708\n",
      "Train Epoch: 3 [12800/27500 (47%)]\tLoss: 0.760092\n",
      "Train Epoch: 3 [16000/27500 (58%)]\tLoss: 0.770524\n",
      "Train Epoch: 3 [19200/27500 (70%)]\tLoss: 0.646667\n",
      "Train Epoch: 3 [22400/27500 (81%)]\tLoss: 0.922330\n",
      "Train Epoch: 3 [25600/27500 (93%)]\tLoss: 0.803864\n",
      "\n",
      "Test set: Avg. loss: 1.0665, Accuracy: 6342/10000 (63%)\n",
      "\n",
      "[[416  36 262  39   5  20   7  54  51 110]\n",
      " [  1 886   3  12   0   4   7   5   2  80]\n",
      " [ 13   6 625  92  14 100  91  49   2   8]\n",
      " [  0  11  76 513  12 280  65  20   6  17]\n",
      " [  9  11 168 137 265 121 139 142   5   3]\n",
      " [  1   7  55 147   9 720  20  32   2   7]\n",
      " [  1   9  37  92   1  34 820   4   0   2]\n",
      " [  1   4  35  55  11 143   8 735   2   6]\n",
      " [105 114  49  41   3  16  13  11 539 109]\n",
      " [  3  80   6  28   0  17  11  24   8 823]]\n",
      "percision:\n",
      "[0.41599958 0.88599911 0.62499938 0.51299949 0.26499974 0.71999928\n",
      " 0.81999918 0.73499927 0.53899946 0.82299918]\n",
      "recall:\n",
      "[0.75636226 0.76116773 0.47492365 0.44377124 0.82812241 0.49484502\n",
      " 0.69432625 0.68308487 0.87358043 0.70643716]\n",
      "Train Epoch: 4 [0/27500 (0%)]\tLoss: 0.605397\n",
      "Train Epoch: 4 [3200/27500 (12%)]\tLoss: 0.632122\n",
      "Train Epoch: 4 [6400/27500 (23%)]\tLoss: 0.650926\n",
      "Train Epoch: 4 [9600/27500 (35%)]\tLoss: 0.627593\n",
      "Train Epoch: 4 [12800/27500 (47%)]\tLoss: 0.550550\n",
      "Train Epoch: 4 [16000/27500 (58%)]\tLoss: 0.633281\n",
      "Train Epoch: 4 [19200/27500 (70%)]\tLoss: 0.741194\n",
      "Train Epoch: 4 [22400/27500 (81%)]\tLoss: 0.607122\n",
      "Train Epoch: 4 [25600/27500 (93%)]\tLoss: 0.756430\n",
      "\n",
      "Test set: Avg. loss: 0.9521, Accuracy: 6717/10000 (67%)\n",
      "\n",
      "[[451  36 242  28   7  10   5  14 109  98]\n",
      " [  2 870   6   5   2   8   3   4  10  90]\n",
      " [ 18   9 816  21  16  42  38  23   5  12]\n",
      " [  1  14 202 489  21 163  51  27   3  29]\n",
      " [  9   9 282  75 369  41  88 107  11   9]\n",
      " [  0   7 140 151  11 608  23  44   2  14]\n",
      " [  0   8  94  69   1  24 789   7   1   7]\n",
      " [  3   4  92  33  16  75   4 729   1  43]\n",
      " [ 47  65  40  24   4  17   6   1 727  69]\n",
      " [ 11  73  13   7   1   1   4   5  16 869]]\n",
      "percision:\n",
      "[0.45099955 0.86999913 0.81599918 0.48899951 0.36899963 0.60799939\n",
      " 0.78899921 0.72899927 0.72699927 0.86899913]\n",
      "recall:\n",
      "[0.83210179 0.79451982 0.42345593 0.542128   0.82365888 0.61476176\n",
      " 0.78041466 0.75858402 0.821468   0.70080589]\n",
      "Train Epoch: 5 [0/27500 (0%)]\tLoss: 0.587307\n",
      "Train Epoch: 5 [3200/27500 (12%)]\tLoss: 0.504009\n",
      "Train Epoch: 5 [6400/27500 (23%)]\tLoss: 0.443535\n",
      "Train Epoch: 5 [9600/27500 (35%)]\tLoss: 0.437169\n",
      "Train Epoch: 5 [12800/27500 (47%)]\tLoss: 0.756422\n",
      "Train Epoch: 5 [16000/27500 (58%)]\tLoss: 0.874156\n",
      "Train Epoch: 5 [19200/27500 (70%)]\tLoss: 0.737768\n",
      "Train Epoch: 5 [22400/27500 (81%)]\tLoss: 0.505975\n",
      "Train Epoch: 5 [25600/27500 (93%)]\tLoss: 0.861926\n",
      "\n",
      "Test set: Avg. loss: 0.9040, Accuracy: 6974/10000 (69%)\n",
      "\n",
      "[[376  56 107  14  74   3  24  22 226  98]\n",
      " [  0 918   4   3   3   3  17   4   5  43]\n",
      " [ 28   6 655  14  73  46 127  36  10   5]\n",
      " [  1  16 107 401  82 104 204  57  15  13]\n",
      " [  6   2  85  26 654  18 125  71  11   2]\n",
      " [  6   4  57 118  59 586  90  62   8  10]\n",
      " [  0   3  24   7  19   1 935   4   2   5]\n",
      " [  2   3  31  17  60  43  17 817   2   8]\n",
      " [ 13  61  14   6  13   1  14   8 808  62]\n",
      " [  0  79   5   8  10   3  24  25  22 824]]\n",
      "percision:\n",
      "[0.37599962 0.91799908 0.65499935 0.4009996  0.65399935 0.58599941\n",
      " 0.93499907 0.81699918 0.80799919 0.82399918]\n",
      "recall:\n",
      "[0.87036836 0.79965087 0.60146869 0.6530934  0.62464124 0.72524663\n",
      " 0.59289753 0.73869734 0.72858365 0.77009274]\n",
      "Train Epoch: 6 [0/27500 (0%)]\tLoss: 0.362094\n",
      "Train Epoch: 6 [3200/27500 (12%)]\tLoss: 0.446069\n",
      "Train Epoch: 6 [6400/27500 (23%)]\tLoss: 0.502428\n",
      "Train Epoch: 6 [9600/27500 (35%)]\tLoss: 0.752903\n",
      "Train Epoch: 6 [12800/27500 (47%)]\tLoss: 0.515087\n",
      "Train Epoch: 6 [16000/27500 (58%)]\tLoss: 0.417764\n",
      "Train Epoch: 6 [19200/27500 (70%)]\tLoss: 0.519641\n",
      "Train Epoch: 6 [22400/27500 (81%)]\tLoss: 0.517974\n",
      "Train Epoch: 6 [25600/27500 (93%)]\tLoss: 0.492964\n",
      "\n",
      "Test set: Avg. loss: 0.9337, Accuracy: 7011/10000 (70%)\n",
      "\n",
      "[[418  34 146  67  37  18  11  11 136 122]\n",
      " [  1 819   2   6   1   1  14   2   7 147]\n",
      " [ 20   3 730  39  39  32  96  20   8  13]\n",
      " [  1   8 112 562  36 114 115  22   7  23]\n",
      " [  4   1 133  71 583  13 117  60   9   9]\n",
      " [  1   2  80 206  40 529  90  37   2  13]\n",
      " [  0   3  28  33  10   1 919   0   4   2]\n",
      " [  4   3  58  70  47  28  24 738   1  27]\n",
      " [ 17  39  24  27   7   4  12   7 783  80]\n",
      " [  0  25  10  12   2   2   7   2  10 930]]\n",
      "percision:\n",
      "[0.41799958 0.81899918 0.72999927 0.56199944 0.58299942 0.52899947\n",
      " 0.91899908 0.73799926 0.78299922 0.92999907]\n",
      "recall:\n",
      "[0.89699378 0.87406524 0.55177585 0.51418068 0.72693176 0.71293704\n",
      " 0.65409206 0.82091121 0.80971995 0.68081941]\n",
      "Train Epoch: 7 [0/27500 (0%)]\tLoss: 0.452678\n",
      "Train Epoch: 7 [3200/27500 (12%)]\tLoss: 0.412368\n",
      "Train Epoch: 7 [6400/27500 (23%)]\tLoss: 0.280028\n",
      "Train Epoch: 7 [9600/27500 (35%)]\tLoss: 0.481892\n",
      "Train Epoch: 7 [12800/27500 (47%)]\tLoss: 0.474697\n",
      "Train Epoch: 7 [16000/27500 (58%)]\tLoss: 0.415299\n",
      "Train Epoch: 7 [19200/27500 (70%)]\tLoss: 0.627910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [22400/27500 (81%)]\tLoss: 0.395281\n",
      "Train Epoch: 7 [25600/27500 (93%)]\tLoss: 0.645254\n",
      "\n",
      "Test set: Avg. loss: 0.9127, Accuracy: 7088/10000 (70%)\n",
      "\n",
      "[[374  33 311  37  40  15  17  29  54  90]\n",
      " [  1 899   5   5   1   6  10   5   6  62]\n",
      " [  4   4 754  35  31  67  69  20   4  12]\n",
      " [  1   8 102 510  33 210  83  25   2  26]\n",
      " [  1   2 138  74 535  59  99  76   7   9]\n",
      " [  1   4  51 109  13 722  48  42   1   9]\n",
      " [  0   4  42  34   5  19 888   3   2   3]\n",
      " [  2   6  34  28  29 106  15 765   3  12]\n",
      " [ 35  42  64  24   4   9  14   8 758  42]\n",
      " [  5  63   7   8   1   6   9   7  11 883]]\n",
      "percision:\n",
      "[0.37399963 0.8989991  0.75399925 0.50999949 0.53499947 0.72199928\n",
      " 0.88799911 0.76499924 0.75799924 0.88299912]\n",
      "recall:\n",
      "[0.88207339 0.84413066 0.49999967 0.59027709 0.77312027 0.59228828\n",
      " 0.70926461 0.78061145 0.89386687 0.76916309]\n",
      "Train Epoch: 8 [0/27500 (0%)]\tLoss: 0.336521\n",
      "Train Epoch: 8 [3200/27500 (12%)]\tLoss: 0.305963\n",
      "Train Epoch: 8 [6400/27500 (23%)]\tLoss: 0.354917\n",
      "Train Epoch: 8 [9600/27500 (35%)]\tLoss: 0.475519\n",
      "Train Epoch: 8 [12800/27500 (47%)]\tLoss: 0.340335\n",
      "Train Epoch: 8 [16000/27500 (58%)]\tLoss: 0.378111\n",
      "Train Epoch: 8 [19200/27500 (70%)]\tLoss: 0.403047\n",
      "Train Epoch: 8 [22400/27500 (81%)]\tLoss: 0.222990\n",
      "Train Epoch: 8 [25600/27500 (93%)]\tLoss: 0.352186\n",
      "\n",
      "Test set: Avg. loss: 0.8513, Accuracy: 7273/10000 (72%)\n",
      "\n",
      "[[563  42 134  60  32   8   6  22  77  56]\n",
      " [  2 933   6   8   1   2   7   1   5  35]\n",
      " [ 34   8 717  65  42  49  47  32   3   3]\n",
      " [  3   9  64 643  57 145  47  20   5   7]\n",
      " [  8   4 118 102 617  23  60  60   6   2]\n",
      " [  4   4  61 194  34 632  21  49   0   1]\n",
      " [  1   9  49  79  19  14 820   6   1   2]\n",
      " [  6   4  29  53  46  55   6 796   1   4]\n",
      " [ 51  69  26  44   8   7  11   5 755  24]\n",
      " [ 10 110   9  24   5   7  10  13  15 797]]\n",
      "percision:\n",
      "[0.56299944 0.93299907 0.71699928 0.64299936 0.61699938 0.63199937\n",
      " 0.81999918 0.7959992  0.75499925 0.7969992 ]\n",
      "recall:\n",
      "[0.82551199 0.78271746 0.59109597 0.50550275 0.71660776 0.67091224\n",
      " 0.79226977 0.7928279  0.86981467 0.85606782]\n",
      "Train Epoch: 9 [0/27500 (0%)]\tLoss: 0.409858\n",
      "Train Epoch: 9 [3200/27500 (12%)]\tLoss: 0.230914\n",
      "Train Epoch: 9 [6400/27500 (23%)]\tLoss: 0.298848\n",
      "Train Epoch: 9 [9600/27500 (35%)]\tLoss: 0.181746\n",
      "Train Epoch: 9 [12800/27500 (47%)]\tLoss: 0.431503\n",
      "Train Epoch: 9 [16000/27500 (58%)]\tLoss: 0.328088\n",
      "Train Epoch: 9 [19200/27500 (70%)]\tLoss: 0.247049\n",
      "Train Epoch: 9 [22400/27500 (81%)]\tLoss: 0.420397\n",
      "Train Epoch: 9 [25600/27500 (93%)]\tLoss: 0.322908\n",
      "\n",
      "Test set: Avg. loss: 0.9874, Accuracy: 7141/10000 (71%)\n",
      "\n",
      "[[425  27 164  65  43   2  14  15 119 126]\n",
      " [  1 903   6   6   0   3   4   0  10  67]\n",
      " [ 12   6 730  81  49  26  55  19   9  13]\n",
      " [  0  15  95 711  36  50  56  12   7  18]\n",
      " [  6   4  96 147 609  14  61  45   8  10]\n",
      " [  1   3  76 283  29 513  41  33   7  14]\n",
      " [  2   9  48  62   7   5 849   2   6  10]\n",
      " [  2   4  49 102  54  25   8 722   3  31]\n",
      " [ 20  47  22  24   7   3   9   6 788  74]\n",
      " [  2  67   5  11   3   3   4   3  11 891]]\n",
      "percision:\n",
      "[0.42499958 0.9029991  0.72999927 0.71099929 0.60899939 0.51299949\n",
      " 0.84899915 0.72199928 0.78799921 0.89099911]\n",
      "recall:\n",
      "[0.90233354 0.8322573  0.5654527  0.47654124 0.7275977  0.79658261\n",
      " 0.77111647 0.84247276 0.81404875 0.71052575]\n",
      "Train Epoch: 10 [0/27500 (0%)]\tLoss: 0.232030\n",
      "Train Epoch: 10 [3200/27500 (12%)]\tLoss: 0.161467\n",
      "Train Epoch: 10 [6400/27500 (23%)]\tLoss: 0.192551\n",
      "Train Epoch: 10 [9600/27500 (35%)]\tLoss: 0.370453\n",
      "Train Epoch: 10 [12800/27500 (47%)]\tLoss: 0.270452\n",
      "Train Epoch: 10 [16000/27500 (58%)]\tLoss: 0.386380\n",
      "Train Epoch: 10 [19200/27500 (70%)]\tLoss: 0.327546\n",
      "Train Epoch: 10 [22400/27500 (81%)]\tLoss: 0.188343\n",
      "Train Epoch: 10 [25600/27500 (93%)]\tLoss: 0.233759\n",
      "\n",
      "Test set: Avg. loss: 1.0788, Accuracy: 7092/10000 (70%)\n",
      "\n",
      "[[487  34 188  82  39   1  25  18  41  85]\n",
      " [  4 876   6  10   2   1  10   0   6  85]\n",
      " [ 14   7 695  97  61  20  79  21   1   5]\n",
      " [  4   6  62 740  40  36  76  22   1  13]\n",
      " [  2   1  86 164 617   5  63  54   1   7]\n",
      " [  2   5  55 336  42 465  48  35   2  10]\n",
      " [  0   3  23  76   9   3 879   4   1   2]\n",
      " [  1   3  36  99  49  18  14 764   2  14]\n",
      " [ 78  58  46  43  10   2  16  10 684  53]\n",
      " [  3  50   7  24   4   1  11   5  10 885]]\n",
      "percision:\n",
      "[0.48699951 0.87599912 0.69499931 0.73999926 0.61699938 0.46499954\n",
      " 0.87899912 0.76399924 0.68399932 0.88499912]\n",
      "recall:\n",
      "[0.81848602 0.83988414 0.57724205 0.44284833 0.7067575  0.84238978\n",
      " 0.71990113 0.818863   0.9132164  0.76358864]\n",
      "Train Epoch: 11 [0/27500 (0%)]\tLoss: 0.193934\n",
      "Train Epoch: 11 [3200/27500 (12%)]\tLoss: 0.092660\n",
      "Train Epoch: 11 [6400/27500 (23%)]\tLoss: 0.077650\n",
      "Train Epoch: 11 [9600/27500 (35%)]\tLoss: 0.181152\n",
      "Train Epoch: 11 [12800/27500 (47%)]\tLoss: 0.198885\n",
      "Train Epoch: 11 [16000/27500 (58%)]\tLoss: 0.188442\n",
      "Train Epoch: 11 [19200/27500 (70%)]\tLoss: 0.267118\n",
      "Train Epoch: 11 [22400/27500 (81%)]\tLoss: 0.206602\n",
      "Train Epoch: 11 [25600/27500 (93%)]\tLoss: 0.209207\n",
      "\n",
      "Test set: Avg. loss: 1.1052, Accuracy: 7084/10000 (70%)\n",
      "\n",
      "[[472  39 155  90  18  15   4  17  70 120]\n",
      " [  1 895   4  10   1   4   6   1   9  69]\n",
      " [ 13  12 668 136  32  52  41  30   5  11]\n",
      " [  5   9  41 744  22  88  26  36   4  25]\n",
      " [  7  10  79 179 541  22  39 108   6   9]\n",
      " [  1   6  31 300  19 561  12  55   5  10]\n",
      " [  1   6  40 143   9  15 766   2   5  13]\n",
      " [  6   2  20  87  20  44   3 781   5  32]\n",
      " [ 59  38  28  44   3   4   7   3 750  64]\n",
      " [  5  52   1  15   1   3   4   2  11 906]]\n",
      "percision:\n",
      "[0.47199953 0.89499911 0.66799933 0.74399926 0.54099946 0.56099944\n",
      " 0.76599923 0.78099922 0.74999925 0.90599909]\n",
      "recall:\n",
      "[0.82806872 0.83723027 0.62605377 0.42562905 0.81231109 0.69430607\n",
      " 0.84361141 0.75458864 0.86206797 0.71961817]\n",
      "Train Epoch: 12 [0/27500 (0%)]\tLoss: 0.062949\n",
      "Train Epoch: 12 [3200/27500 (12%)]\tLoss: 0.164789\n",
      "Train Epoch: 12 [6400/27500 (23%)]\tLoss: 0.233668\n",
      "Train Epoch: 12 [9600/27500 (35%)]\tLoss: 0.239276\n",
      "Train Epoch: 12 [12800/27500 (47%)]\tLoss: 0.101852\n",
      "Train Epoch: 12 [16000/27500 (58%)]\tLoss: 0.190125\n",
      "Train Epoch: 12 [19200/27500 (70%)]\tLoss: 0.252361\n",
      "Train Epoch: 12 [22400/27500 (81%)]\tLoss: 0.137557\n",
      "Train Epoch: 12 [25600/27500 (93%)]\tLoss: 0.294703\n",
      "\n",
      "Test set: Avg. loss: 1.1132, Accuracy: 7128/10000 (71%)\n",
      "\n",
      "[[518  55 220  63  27   9   7  19  34  48]\n",
      " [  3 938   9   7   0   2   4   1   1  35]\n",
      " [ 15   8 749  65  47  35  57  19   2   3]\n",
      " [  4   6 107 649  39  98  58  31   1   7]\n",
      " [  5   2 112  79 660  23  47  61   5   6]\n",
      " [  2   6  88 227  27 582  27  35   2   4]\n",
      " [  1   7  67  53  19  10 837   3   1   2]\n",
      " [  6   6  41  75  53  52  10 752   2   3]\n",
      " [ 95 111  51  30   4   5   7   9 645  43]\n",
      " [  9 133  13  16   5   6   4  13   3 798]]\n",
      "percision:\n",
      "[0.51799948 0.93799906 0.74899925 0.64899935 0.65999934 0.58199942\n",
      " 0.83699916 0.75199925 0.64499936 0.7979992 ]\n",
      "recall:\n",
      "[0.78723285 0.7374208  0.51406965 0.51344896 0.74914784 0.70802834\n",
      " 0.79111456 0.79745409 0.92672281 0.84088426]\n",
      "Train Epoch: 13 [0/27500 (0%)]\tLoss: 0.154558\n",
      "Train Epoch: 13 [3200/27500 (12%)]\tLoss: 0.075397\n",
      "Train Epoch: 13 [6400/27500 (23%)]\tLoss: 0.076771\n",
      "Train Epoch: 13 [9600/27500 (35%)]\tLoss: 0.138772\n",
      "Train Epoch: 13 [12800/27500 (47%)]\tLoss: 0.025687\n",
      "Train Epoch: 13 [16000/27500 (58%)]\tLoss: 0.086641\n",
      "Train Epoch: 13 [19200/27500 (70%)]\tLoss: 0.155135\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-5341231284d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-20df77d4b376>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlog_interval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mlp/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mlp/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# distribtion [ 500, 4000, 3500, 3000, 1500, 2500, 5000, 2000, 1000, 4500]\n",
    "n_epochs = 100\n",
    "test()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percision:\n",
    "# balance:   [0.7899 0.9029 0.5999 0.6079 0.6689 0.5459 0.8569 0.8789 0.7979 0.8489]\n",
    "# unbalance:\n",
    "# recall:\n",
    "# balance:   [0.7692 0.8376 0.7317 0.5795 0.7295 0.7531 0.7748 0.6589 0.8711 0.8258]\n",
    "# unbalance: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.array(dataset_dic['CIFAR10_linear_unbalanced_1'].targets)==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.load(\"./data/CIFAR10_linear_unbalanced_1.npy\") == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
