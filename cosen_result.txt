Namespace(batch_size=100, cost_sensitive_mode=False, dataset_name='MNIST', eval_index_path='', experiment_name='exp_1', image_num_channels=3, model_name='Custom_07', num_classes=10, num_epochs=5, seed=7112018, train_index_path='', use_gpu=True, weight_decay_coefficient=0)
Namespace(batch_size=100, cost_sensitive_mode=False, dataset_name='MNIST', eval_index_path='', experiment_name='exp_1', image_num_channels=3, model_name='Custom_07', num_classes=10, num_epochs=5, seed=7112018, train_index_path='', use_gpu=True, weight_decay_coefficient=0)
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
use CPU
cpu
here
System learnable parameters
model.conv_1.0.weight torch.Size([32, 3, 5, 5])
model.conv_1.0.bias torch.Size([32])
model.conv_1.2.weight torch.Size([32])
model.conv_1.2.bias torch.Size([32])
model.conv_2.0.weight torch.Size([64, 32, 3, 3])
model.conv_2.0.bias torch.Size([64])
model.conv_2.2.weight torch.Size([64])
model.conv_2.2.bias torch.Size([64])
model.conv_3.0.weight torch.Size([128, 64, 3, 3])
model.conv_3.0.bias torch.Size([128])
model.conv_3.2.weight torch.Size([128])
model.conv_3.2.bias torch.Size([128])
model.linear.1.weight torch.Size([128, 512])
model.linear.1.bias torch.Size([128])
model.linear.2.weight torch.Size([128])
model.linear.2.bias torch.Size([128])
model.output_layer.weight torch.Size([10, 128])
model.output_layer.bias torch.Size([10])
Total number of parameters 162442
Total number of conv layers 6
Total number of linear layers 2



Epoch 0: train_acc_0.4729_train_loss_1.5266_val_acc_0.5368_val_loss_1.2878_val_sens_0.5109 epoch time 31.0591 seconds



tada!
Epoch 1: train_acc_0.5784_train_loss_1.6255_val_acc_0.6014_val_loss_1.1080_val_sens_0.5696 epoch time 31.0039 seconds



Epoch 2: train_acc_0.6274_train_loss_1.6220_val_acc_0.6587_val_loss_0.9608_val_sens_0.6244 epoch time 30.9907 seconds



Epoch 3: train_acc_0.6614_train_loss_1.5443_val_acc_0.6832_val_loss_0.9103_val_sens_0.6482 epoch time 30.8229 seconds




Epoch 4: train_acc_0.6839_train_loss_1.4960_val_acc_0.7033_val_loss_0.8768_val_sens_0.6665 epoch time 36.9544 seconds

tada!

tada!

Epoch 5: train_acc_0.7053_train_loss_1.4393_val_acc_0.7186_val_loss_0.8475_val_sens_0.6819 epoch time 31.0278 seconds



tada!
Epoch 6: train_acc_0.7220_train_loss_1.3676_val_acc_0.7305_val_loss_0.8165_val_sens_0.6947 epoch time 30.5242 seconds



tada!
Epoch 7: train_acc_0.7347_train_loss_1.3056_val_acc_0.7363_val_loss_0.7967_val_sens_0.6990 epoch time 30.8740 seconds



Epoch 8: train_acc_0.7479_train_loss_1.2494_val_acc_0.7465_val_loss_0.7726_val_sens_0.7084 epoch time 30.6734 seconds


tada!


Epoch 9: train_acc_0.7557_train_loss_1.2181_val_acc_0.7515_val_loss_0.7637_val_sens_0.7133 epoch time 36.5997 seconds


tada!

Epoch 10: train_acc_0.7639_train_loss_1.1715_val_acc_0.7464_val_loss_0.7950_val_sens_0.7078 epoch time 31.0584 seconds

tada!

tada!

Epoch 11: train_acc_0.7736_train_loss_1.1247_val_acc_0.7549_val_loss_0.7749_val_sens_0.7165 epoch time 31.4604 seconds

tada!


tada!
Epoch 12: train_acc_0.7814_train_loss_1.0892_val_acc_0.7605_val_loss_0.7610_val_sens_0.7241 epoch time 30.9058 seconds

tada!


tada!

tada!
Epoch 13: train_acc_0.7861_train_loss_1.0621_val_acc_0.7648_val_loss_0.7400_val_sens_0.7265 epoch time 36.8234 seconds

tada!

tada!

tada!
Epoch 14: train_acc_0.7979_train_loss_1.0100_val_acc_0.7650_val_loss_0.7456_val_sens_0.7263 epoch time 30.9163 seconds

tada!

tada!

Epoch 15: train_acc_0.8026_train_loss_0.9921_val_acc_0.7636_val_loss_0.7682_val_sens_0.7224 epoch time 31.4855 seconds



tada!
Epoch 16: train_acc_0.8065_train_loss_0.9601_val_acc_0.7669_val_loss_0.7479_val_sens_0.7280 epoch time 30.7397 seconds



tada!
Epoch 17: train_acc_0.8130_train_loss_0.9265_val_acc_0.7761_val_loss_0.7211_val_sens_0.7387 epoch time 38.3275 seconds

tada!


tada!

tada!
Epoch 18: train_acc_0.8199_train_loss_0.9009_val_acc_0.7691_val_loss_0.7589_val_sens_0.7301 epoch time 71.7273 seconds

tada!


Epoch 19: train_acc_0.8231_train_loss_0.8854_val_acc_0.7759_val_loss_0.7484_val_sens_0.7350 epoch time 59.7897 seconds

tada!

tada!

Epoch 20: train_acc_0.8265_train_loss_0.8624_val_acc_0.7765_val_loss_0.7416_val_sens_0.7382 epoch time 57.6519 seconds


tada!

tada!
Epoch 21: train_acc_0.8334_train_loss_0.8292_val_acc_0.7773_val_loss_0.7543_val_sens_0.7382 epoch time 64.4731 seconds




tada!
Epoch 22: train_acc_0.8345_train_loss_0.8207_val_acc_0.7806_val_loss_0.7404_val_sens_0.7403 epoch time 75.0528 seconds


tada!

Epoch 23: train_acc_0.8405_train_loss_0.7883_val_acc_0.7775_val_loss_0.7641_val_sens_0.7373 epoch time 57.6104 seconds

tada!


Epoch 24: train_acc_0.8432_train_loss_0.7754_val_acc_0.7806_val_loss_0.7475_val_sens_0.7385 epoch time 59.0024 seconds

tada!

tada!

Epoch 25: train_acc_0.8487_train_loss_0.7472_val_acc_0.7808_val_loss_0.7515_val_sens_0.7412 epoch time 58.6871 seconds

tada!

tada!

Epoch 26: train_acc_0.8533_train_loss_0.7326_val_acc_0.7865_val_loss_0.7552_val_sens_0.7500 epoch time 57.6873 seconds

tada!



tada!
Epoch 27: train_acc_0.8556_train_loss_0.7192_val_acc_0.7843_val_loss_0.7464_val_sens_0.7460 epoch time 66.0317 seconds

tada!

tada!

tada!
Epoch 28: train_acc_0.8579_train_loss_0.7001_val_acc_0.7856_val_loss_0.7496_val_sens_0.7457 epoch time 57.8596 seconds



tada!
Epoch 29: train_acc_0.8616_train_loss_0.6836_val_acc_0.7865_val_loss_0.7481_val_sens_0.7473 epoch time 55.9831 seconds


tada!

Epoch 30: train_acc_0.8686_train_loss_0.6561_val_acc_0.7870_val_loss_0.7566_val_sens_0.7460 epoch time 57.3627 seconds


tada!

tada!

Epoch 31: train_acc_0.8700_train_loss_0.6482_val_acc_0.7861_val_loss_0.7689_val_sens_0.7452 epoch time 65.1110 seconds



tada!
Epoch 32: train_acc_0.8754_train_loss_0.6247_val_acc_0.7873_val_loss_0.7702_val_sens_0.7443 epoch time 58.5256 seconds

tada!

tada!

Epoch 33: train_acc_0.8785_train_loss_0.6013_val_acc_0.7909_val_loss_0.7675_val_sens_0.7494 epoch time 57.2095 seconds


tada!

tada!
Epoch 34: train_acc_0.8779_train_loss_0.5976_val_acc_0.7913_val_loss_0.7794_val_sens_0.7488 epoch time 57.0362 seconds

tada!

tada!

Epoch 35: train_acc_0.8819_train_loss_0.5834_val_acc_0.7892_val_loss_0.7844_val_sens_0.7501 epoch time 56.8188 seconds

tada!

tada!


tada!
Epoch 36: train_acc_0.8822_train_loss_0.5795_val_acc_0.7896_val_loss_0.7885_val_sens_0.7489 epoch time 63.9848 seconds


tada!

Epoch 37: train_acc_0.8852_train_loss_0.5573_val_acc_0.7900_val_loss_0.8002_val_sens_0.7503 epoch time 56.7977 seconds

tada!


tada!
Epoch 38: train_acc_0.8935_train_loss_0.5336_val_acc_0.7948_val_loss_0.7898_val_sens_0.7528 epoch time 57.4412 seconds

tada!

tada!

Epoch 39: train_acc_0.8925_train_loss_0.5293_val_acc_0.7941_val_loss_0.7964_val_sens_0.7544 epoch time 57.2494 seconds

tada!

tada!

tada!

Epoch 40: train_acc_0.8952_train_loss_0.5128_val_acc_0.7947_val_loss_0.8023_val_sens_0.7551 epoch time 65.0598 seconds



tada!
Epoch 41: train_acc_0.8961_train_loss_0.5108_val_acc_0.7951_val_loss_0.7908_val_sens_0.7521 epoch time 56.6104 seconds

tada!

tada!

tada!
Epoch 42: train_acc_0.8966_train_loss_0.5052_val_acc_0.7933_val_loss_0.8160_val_sens_0.7554 epoch time 56.0103 seconds

tada!


tada!
Epoch 43: train_acc_0.8991_train_loss_0.4890_val_acc_0.7954_val_loss_0.8156_val_sens_0.7553 epoch time 56.8241 seconds

tada!


tada!
Epoch 44: train_acc_0.9038_train_loss_0.4785_val_acc_0.7947_val_loss_0.8117_val_sens_0.7552 epoch time 53.7933 seconds



tada!

tada!
Epoch 45: train_acc_0.9036_train_loss_0.4734_val_acc_0.7956_val_loss_0.8079_val_sens_0.7555 epoch time 65.3399 seconds


tada!

Epoch 46: train_acc_0.9069_train_loss_0.4604_val_acc_0.7912_val_loss_0.8256_val_sens_0.7511 epoch time 57.0263 seconds



tada!
Epoch 47: train_acc_0.9090_train_loss_0.4536_val_acc_0.7967_val_loss_0.8134_val_sens_0.7585 epoch time 56.1827 seconds


tada!

Epoch 48: train_acc_0.9099_train_loss_0.4440_val_acc_0.7944_val_loss_0.8266_val_sens_0.7575 epoch time 55.6224 seconds

tada!

tada!

tada!

tada!
Epoch 49: train_acc_0.9108_train_loss_0.4319_val_acc_0.7946_val_loss_0.8324_val_sens_0.7569 epoch time 65.0937 seconds

tada!

tada!

Epoch 50: train_acc_0.9121_train_loss_0.4333_val_acc_0.7969_val_loss_0.8299_val_sens_0.7575 epoch time 56.4781 seconds

tada!

tada!

tada!
Epoch 51: train_acc_0.9138_train_loss_0.4215_val_acc_0.7964_val_loss_0.8377_val_sens_0.7584 epoch time 56.6275 seconds


tada!

Epoch 52: train_acc_0.9166_train_loss_0.4155_val_acc_0.7964_val_loss_0.8438_val_sens_0.7582 epoch time 55.5192 seconds



tada!
Epoch 53: train_acc_0.9157_train_loss_0.4172_val_acc_0.7971_val_loss_0.8345_val_sens_0.7578 epoch time 55.1286 seconds

tada!



tada!
Epoch 54: train_acc_0.9183_train_loss_0.3981_val_acc_0.7972_val_loss_0.8356_val_sens_0.7576 epoch time 66.9401 seconds


tada!

tada!
Epoch 55: train_acc_0.9162_train_loss_0.4134_val_acc_0.7949_val_loss_0.8491_val_sens_0.7567 epoch time 63.0862 seconds

tada!

tada!

Epoch 56: train_acc_0.9205_train_loss_0.3883_val_acc_0.7954_val_loss_0.8478_val_sens_0.7558 epoch time 55.9703 seconds



Epoch 57: train_acc_0.9204_train_loss_0.3926_val_acc_0.7977_val_loss_0.8364_val_sens_0.7609 epoch time 56.3568 seconds


tada!

tada!
Epoch 58: train_acc_0.9190_train_loss_0.3955_val_acc_0.7959_val_loss_0.8489_val_sens_0.7587 epoch time 56.2261 seconds

tada!

tada!


Epoch 59: train_acc_0.9185_train_loss_0.3945_val_acc_0.7967_val_loss_0.8487_val_sens_0.7574 epoch time 64.5155 seconds


tada!

Epoch 60: train_acc_0.9174_train_loss_0.3999_val_acc_0.7951_val_loss_0.8549_val_sens_0.7577 epoch time 57.8063 seconds


tada!

Epoch 61: train_acc_0.9195_train_loss_0.3908_val_acc_0.7966_val_loss_0.8578_val_sens_0.7568 epoch time 58.9256 seconds

tada!


tada!
Epoch 62: train_acc_0.9203_train_loss_0.3866_val_acc_0.7973_val_loss_0.8491_val_sens_0.7583 epoch time 56.4797 seconds
Generating test set evaluation metrics
[[0.01787834 0.13343755 0.13251874 0.12683785 0.12547104 0.12697208
  0.12691872 0.12668538 0.05580152 0.05602018]
 [0.13446643 0.01767335 0.12407648 0.12603617 0.12346519 0.12468639
  0.12820001 0.12414794 0.05546234 0.05558459]
 [0.13416205 0.13076613 0.05663515 0.13523488 0.13527452 0.13650614
  0.13465364 0.13069004 0.05516142 0.05576746]
 [0.13429108 0.13118854 0.13591333 0.07039169 0.13175538 0.0874807
  0.13320876 0.13072007 0.05609573 0.05644135]
 [0.13689857 0.12849832 0.13720001 0.13417497 0.04502225 0.13396936
  0.13194214 0.13624895 0.05534678 0.05594507]
 [0.12796219 0.12658549 0.13441338 0.13286812 0.13149827 0.02034888
  0.13351825 0.13273624 0.05531823 0.05655305]
 [0.12784331 0.13042589 0.13287406 0.13496898 0.12959517 0.12989879
  0.01808952 0.12452431 0.05545973 0.05624297]
 [0.13182103 0.12900536 0.12961713 0.13290223 0.13461809 0.13027452
  0.12718558 0.02041865 0.0555798  0.05588623]
 [0.02081605 0.02601294 0.03234781 0.0326833  0.03021703 0.03260065
  0.03134975 0.03158384 0.02026459 0.02024999]
 [0.03949194 0.01850905 0.03476224 0.03684815 0.03644926 0.03763872
  0.03624689 0.03669637 0.02026717 0.02026459]]
use CPU
cpu
here
System learnable parameters
model.conv_1.0.weight torch.Size([32, 3, 5, 5])
model.conv_1.0.bias torch.Size([32])
model.conv_1.2.weight torch.Size([32])
model.conv_1.2.bias torch.Size([32])
model.conv_2.0.weight torch.Size([64, 32, 3, 3])
model.conv_2.0.bias torch.Size([64])
model.conv_2.2.weight torch.Size([64])
model.conv_2.2.bias torch.Size([64])
model.conv_3.0.weight torch.Size([128, 64, 3, 3])
model.conv_3.0.bias torch.Size([128])
model.conv_3.2.weight torch.Size([128])
model.conv_3.2.bias torch.Size([128])
model.linear.1.weight torch.Size([128, 512])
model.linear.1.bias torch.Size([128])
model.linear.2.weight torch.Size([128])
model.linear.2.bias torch.Size([128])
model.output_layer.weight torch.Size([10, 128])
model.output_layer.bias torch.Size([10])
Total number of parameters 162442
Total number of conv layers 6
Total number of linear layers 2



Epoch 0: train_acc_0.8733_train_loss_0.4007_val_acc_0.7770_val_loss_0.8409_val_sens_0.7392 epoch time 59.4509 seconds



Epoch 1: train_acc_0.8715_train_loss_0.4197_val_acc_0.7783_val_loss_0.7703_val_sens_0.7399 epoch time 57.4675 seconds



Epoch 2: train_acc_0.8713_train_loss_0.4621_val_acc_0.7800_val_loss_0.7531_val_sens_0.7358 epoch time 56.1702 seconds

tada!


tada!
Epoch 3: train_acc_0.8707_train_loss_0.4934_val_acc_0.7805_val_loss_0.7502_val_sens_0.7409 epoch time 67.5797 seconds



